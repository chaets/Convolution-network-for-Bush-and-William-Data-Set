# -*- coding: utf-8 -*-
"""William_Cifar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bnFFP7sshWbCGY7QNqaTfwY1aDd1sQY9
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install keras_metrics
!apt-get -qq install -y graphviz && pip install -q py
!pip install pydot

import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_validate,StratifiedKFold
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
import pickle
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation
from keras.callbacks import Callback
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
import keras_metrics
from keras.utils import plot_model
from keras.datasets import cifar10
from sklearn.metrics import f1_score
import tensorflow as tf

X = pd.read_csv("drive/My Drive/Colab Notebooks/X.csv",sep = ' ', header=None,dtype=float)
X = X.values

y = pd.read_csv("drive/My Drive/Colab Notebooks/y_williams_vs_others.csv",sep = ' ', header=None,dtype=float)
y_bush = y.values.ravel()

print("X shape", X.shape)
print('Y William shape', y_bush.shape)

batch_size = 100
num_classes = 2
epochs = 30

# input image dimensions
# img_rows, img_cols = 64, 64

x_train, x_test, y_train, y_test = train_test_split(X, y_bush, test_size=1. / 3, random_state=8854, shuffle = True, stratify = y_bush)

x_train = x_train.reshape(-1,64,64,1)
x_test = x_test.reshape(-1,64,64,1)

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

X_grey_train=tf.image.rgb_to_grayscale(x_train,name=None)
X_grey_test=tf.image.rgb_to_grayscale(x_test,name=None)

X_reshaped_train = tf.image.resize_images(X_grey_train,(64,64))
X_reshaped_test = tf.image.resize_images(X_grey_test,(64,64))

y_train_binary=list()
for i in range(len(y_train)):
 if y_train[i]==5:
   y_train_binary.append(1)
 elif y_train[i]!=5:
   y_train_binary.append(0)

y_test_binary=list()
for i in range(len(y_test)):
 if y_test[i]==5:
   y_test_binary.append(1)
 elif y_test[i]!=5:
   y_test_binary.append(0)

y_train_binary_array=np.asanyarray(y_train_binary)
type(y_train_binary_array)

y_test_binary_array=np.asanyarray(y_test_binary)
type(y_test_binary_array)

init=tf.global_variables_initializer()
sess=tf.Session()
sess.run(init)
X_reshaped_train=X_reshaped_train.eval(session=sess)
X_reshaped_test=X_reshaped_test.eval(session=sess)

model = Sequential()

model.add(Conv2D(64, (3, 3), input_shape=(64,64,1)))
model.add(Activation('tanh'))
model.add(MaxPooling2D(pool_size=(3,3)))

model.add(Conv2D(64, (3,3)))
model.add(Activation('tanh'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3)))
model.add(Activation('tanh'))
model.add(MaxPooling2D(pool_size=(3,3)))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors

model.add(Dense(64))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr = 0.0001), metrics=['accuracy'])

model.fit(X_reshaped_train, y_train_binary_array,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(X_reshaped_train, y_train_binary_array))

s = model.predict_classes(X_reshaped_test)
fscore = f1_score(y_test_binary_array,s)
print(fscore)

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))

s = model.predict_classes(x_train)
fscore_train = f1_score(y_train,s)
print('train f1 = ', fscore_train)

s = model.predict_classes(x_test)
fscore_test = f1_score(y_test,s)
print('test f1 = ', fscore_test)

